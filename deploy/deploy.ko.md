---
layout: default
title: 앱 배포
lang: ko
---

# 앱 배포

MCP 서버를 배포하는 방법을 학습합니다

## 배포 옵션

작동하는 MCP 서버와 컴포넌트 번들이 있으면 안정적인 HTTPS 엔드포인트 뒤에 호스팅합니다. Apps SDK와 잘 작동하는 배포 플랫폼은 다음과 같습니다:

- **관리형 컨테이너** — Fly.io, Render 또는 Railway로 빠른 스핀업과 자동 TLS를 제공합니다.
- **클라우드 서버리스** — Google Cloud Run 또는 Azure Container Apps는 스케일 투 제로가 필요한 경우에 적합하지만, 긴 콜드 스타트가 스트리밍 HTTP를 중단할 수 있다는 점을 염두에 두세요.
- **Kubernetes** — 이미 클러스터를 실행하는 팀을 위한 옵션입니다. 서버 전송 이벤트를 지원하는 인그레스 컨트롤러로 파드를 프론트합니다.

플랫폼에 관계없이 `/mcp`가 응답성을 유지하고, 스트리밍 응답을 지원하며, 오류에 대해 적절한 HTTP 상태 코드를 반환하는지 확인하세요.

## 로컬 개발

개발 중에는 ngrok과 같은 터널을 사용하여 로컬 서버를 ChatGPT에 노출할 수 있습니다:

```bash
ngrok http 2091
# https://<subdomain>.ngrok.app/mcp -> http://127.0.0.1:2091/mcp
```

커넥터를 반복하는 동안 터널을 실행 상태로 유지합니다. 코드를 변경할 때:

- 컴포넌트 번들을 다시 빌드합니다(`npm run build`).
- MCP 서버를 재시작합니다.
- ChatGPT 설정에서 커넥터를 새로고침하여 최신 메타데이터를 가져옵니다.

## 환경 구성

- **시크릿** — API 키나 OAuth 클라이언트 시크릿을 저장소 외부에 저장합니다. 플랫폼별 시크릿 관리자를 사용하고 환경 변수로 주입합니다.
- **로깅** — 도구 호출 ID, 요청 지연 시간, 오류 페이로드를 로깅합니다. 이는 커넥터가 라이브된 후 사용자 보고서를 디버그하는 데 도움이 됩니다.
- **관찰 가능성** — CPU, 메모리, 요청 수를 모니터링하여 배포 규모를 적절히 조정할 수 있습니다.

## 도그푸딩 및 배포

광범위하게 런칭하기 전에:

- **접근 제한** — 안정성을 확신할 때까지 커넥터를 개발자 모드 또는 Statsig 실험 플래그 뒤에 유지합니다.
- **골든 프롬프트 실행** — 계획 중에 작성한 검색 프롬프트를 실행하고 각 릴리스마다 정밀도/재현율 변경 사항을 기록합니다.
- **아티팩트 캡처** — MCP Inspector와 ChatGPT에서 컴포넌트를 보여주는 스크린샷이나 화면 캡처를 기록하여 참조합니다.

프로덕션 준비가 되면 디렉토리 메타데이터를 업데이트하고, 인증 및 스토리지가 올바르게 구성되었는지 확인하고, [릴리스 노트](https://developers.openai.com/apps-sdk/release-notes)에 변경 노트를 게시합니다.

## 다음 단계

- [ChatGPT에서 연결](https://developers.openai.com/apps-sdk/deploy/connect-chatgpt)의 단계를 사용하여 배포된 엔드포인트를 ChatGPT에 연결합니다.
- [통합 테스트](https://developers.openai.com/apps-sdk/deploy/testing) 가이드로 도구 및 텔레메트리를 검증합니다.
- [문제 해결](https://developers.openai.com/apps-sdk/deploy/troubleshooting)을 통해 온콜 대응자가 문제를 빠르게 진단할 수 있도록 문제 해결 플레이북을 준비합니다.
